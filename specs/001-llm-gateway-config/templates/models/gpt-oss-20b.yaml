# GPT-OSS 20B Model Configuration
# Model: gpt-oss-20b-maas
# Publisher: OpenAI (via Vertex AI Model Garden)
# Priority: P3
# Use Case: Cost-effective open-source alternative to GPT models

model_name: gpt-oss-20b
litellm_params:
  model: vertex_ai/openai/gpt-oss-20b-maas
  vertex_project: YOUR_PROJECT_ID        # Replace with your GCP project ID
  vertex_location: us-central1           # Check availability in your region
  
  # Authentication (choose one)
  # Option 1: Use gcloud auth (recommended for development)
  # vertex_credentials: default
  
  # Option 2: Use service account JSON (recommended for production)
  # vertex_credentials: /path/to/service-account-key.json

# Model capabilities
model_info:
  supports_function_calling: true
  supports_reasoning_mode: true
  max_input_tokens: 8192                 # 8K context window
  max_output_tokens: 2048
  parameter_count: 20B                   # Smaller, cost-effective model

# Rate limiting (optional)
# rpm: 40                                # Smaller model = higher throughput
# tpm: 400000                            # Tokens per minute

# Load balancing (optional)
# priority: 5                            # Lower priority (cost optimization)
